\documentclass{rapport}

%--------------------------------------------------
% Packages de base et mise en forme
%--------------------------------------------------
\usepackage{blindtext}
\usepackage{lipsum}
\usepackage{enumitem}
\usepackage{setspace}
\usepackage{changepage}
\usepackage{adjustbox}

%--------------------------------------------------
% Mathématiques et symboles
%--------------------------------------------------
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{eurosym}

%--------------------------------------------------
% Tableaux et couleurs
%--------------------------------------------------
\usepackage{booktabs}
\usepackage[table]{xcolor}
\usepackage{subcaption}

\definecolor{LightGray}{gray}{0.95}
\definecolor{pale_red}{HTML}{F4A7A3}
\definecolor{pale_green}{HTML}{E8F5DC}
\definecolor{pale_violet}{HTML}{E7D8F5}
\definecolor{pale_yellow}{HTML}{F8E68C}
\definecolor{pale_blue}{HTML}{97DAD9}

%--------------------------------------------------
% Graphiques et TikZ
%--------------------------------------------------
\usepackage{tikz}

\newcommand{\verticalquote}[1]{%
    \begin{tikzpicture}[remember picture, overlay]
        \draw[thick,black] (-0.5cm,0) -- (-0.5cm,-0.4cm);
    \end{tikzpicture}%
    \hspace{0.5cm}\itshape#1}

\newcommand{\colorboxsquare}[1]{%
    \tikz \fill[#1] (0,0) rectangle (0.3,0.3);
}

%--------------------------------------------------
% Code, icônes et typographie
%--------------------------------------------------
\usepackage{minted}
\usepackage{fontawesome}
\usepackage{csquotes}

\newcommand{\ttt}[1]{\texttt{#1}}

%--------------------------------------------------
% Bibliographie
%--------------------------------------------------
\usepackage[
    backend=biber,
    style=numeric,
    sorting=none
]{biblatex}

\addbibresource{biblio.bib}

\setlength{\bibitemsep}{\itemsep}
\setlength{\bibparsep}{\parsep}

%--------------------------------------------------
% Commandes personnalisées
%--------------------------------------------------
\newcommand{\myparagraph}[1]{%
    \paragraph{#1} \mbox{} \\
    \vspace{-1em}
}

%--------------------------------------------------
% Listes
%--------------------------------------------------
\setlist[itemize,1]{label={\textbullet}}
\setlist[itemize,2]{label={$\blacktriangleright$}}

%--------------------------------------------------
% Divers / Commentaires
%--------------------------------------------------
% \usepackage{breakurl}


\title{Rapport de protection des données}

\onehalfspacing

\begin{document}


% ========================== Informations du rapport ==========================

\setlogo{images/LogoTPS.png}
\setunif{Télécom Physique Strasbourg}
\setsujet{Rapport de protection des données}
\settitre{Analyse de données cyberphysiques sur la distribution d'eau}
\seteleves{Nathan \textsc{Cerisara}\\Clément \textsc{Desberg}\\Ysée \textsc{Jacquet}\\Lucas \textsc{Levy}}

% ============================== Initialisation ===============================

\fairepagedegarde
\fairemarges

\newpage
% Numérotation
\pagenumbering{roman}
\setcounter{page}{1}

\tabledematieres
\listoffigures
% Table des tableaux (si nécessaire)
\listoftables

\section*{Abréviations employées}

\begin{itemize}
	\item \textbf{CART} : Classification And Regression Trees
    \item \textbf{CNN} : Convolutional Neural Network
	\item \textbf{CSV} : Comma Separated Values
	\item \textbf{FT Transformer} : Feature Tokenizer Transformer
	\item \textbf{KNN} : K-Nearest Neighbors
	\item \textbf{MITM} : Man-In-The-Middle
	\item \textbf{MLP} : Multi-Layer Perceptron
	\item \textbf{MCC} : Matthews Correlation Coefficient
	\item \textbf{NLP} : Natural Language Processing
\end{itemize}

% ============================= Corps du rapport ==============================

\newpage
% Numérotation
\pagenumbering{arabic}
\setcounter{page}{1}

\section*{Introduction}
\addcontentsline{toc}{section}{Introduction}

Ce projet consiste en l'analyse de données cyberphysiques issues d'un système de distribution d'eau potable \cite{dataset}.
L'objectif principal est de développer et d'évaluer des modèles de machine learning capables de détecter et de classer les anomalies dans le système, telles que les attaques informatiques ou les défaillances physiques.
Les consignes du projet prévoient l'implémentation de K-Nearest Neighbors (KNN), Random Forest, XGBoost et Multi-Layer Perceptron (MLP) et Classification And Regression Trees (CART).
Il est également possible de remplacer l'un de ces modèles par un ou plusieurs autres au choix, ce qui a été fait en implémentant des modèles basés sur des transformeurs (Tab Transformer et FT Transformer) ainsi qu'un MLP avec attention à la place du modèle CART.
Finalement, les performances des modèles développés ont été comparées avec celles fournies dans l'article de référence \cite{article_reference}.

%  ---------------------- I. Données ----------------------

\section{Données}

L'ensemble des données comprend 5 fichiers Comma Separated Values (CSV) sur les relevés physiques et 5 fichiers CSV sur les relevés réseau.
Dans chaque cas, il y a un fichier de mesures prises en période normale – sans anomalie – et 4 fichiers de mesures prises en période anormale, avec des anomalies correspondant au type de données (attaques informatiques ou défaillances physiques).
Le sujet de chaque fichier est résumé dans la \hyperref[tab:files]{Table 1} ci-dessous :

\begin{table}[h]
	\centering
	\begin{tabular}{|l|l|}
		\hline
		\textbf{Fichier} & \textbf{Contenu} \\
		\hline
		\texttt{normal.csv}  & Acquisitions du traffic réseau en période normale \\
		\hline
		\texttt{phy\_norm.csv}  & Acquisitions des mesures physiques en période normale \\
		\hline
		\texttt{attack\_1.csv}  & Première acquisition du traffic réseau avec anomalies \\
		\hline
		\texttt{dataset\_att\_1.csv}  & Première acquisition des mesures physiques avec anomalies \\
		\hline
		\texttt{attack\_2.csv}  & Deuxième acquisition du traffic réseau avec anomalies \\
		\hline
		\texttt{dataset\_att\_2.csv}  & Deuxième acquisition des mesures physiques avec anomalies \\
		\hline
		\texttt{attack\_3.csv}  & Troisième acquisition du traffic réseau avec anomalies \\
		\hline
		\texttt{dataset\_att\_3.csv}  & Troisième acquisition des mesures physiques avec anomalies \\
		\hline
		\texttt{attack\_4.csv}  & Quatrième acquisition du traffic réseau avec anomalies \\
		\hline
		\texttt{dataset\_att\_4.csv}  & Quatrième acquisition des mesures physiques avec anomalies \\
		\hline
	\end{tabular}
	\caption{Aperçu des fichiers de données fournis, d'après le fichier fourni \texttt{README.xlsx}}
	\label{tab:files}
	\end{table}

Il y a également des fichiers packet capture (PCAP) fournis pour les données réseau, mais ceux-ci n'ont pas été utilisés dans le cadre de ce projet.

% ------- I.1 Visualisation et analyse des données --------

\subsection{Visualisation et analyse des données}

% -------- I.1.1 Présentation générale des données --------

\subsubsection{Présentation générale des données}

Dans chaque fichier CSV, une ligne représente un ensemble de données collectées à un instant donné, tandis que les colonnes renvoient à différentes informations relevées ou différents dispositifs sur lesquels une mesure a été faite.
Chaque ligne est associée à une étiquette (\texttt{label}) indiquant si les données correspondent à un état normal (étiquette \texttt{normal} ou altérée en \texttt{nomal}) ou à une anomalie (étiquettes \texttt{anomaly}, \texttt{DoS}, \texttt{MITM}, \texttt{scan} ou \texttt{physical fault}).
La répartition globale peut être observée dans la \hyperref[fig:data_repartition]{Figure 1}, tandis que le détail de la répartition des étiquettes peut être consulté dans la \hyperref[tab:labels_repartition]{Table 2}.\\

\begin{figure}[H]
	\centering
	\includegraphics[width=0.75\textwidth]{images/data_repartition.png}
	\caption{Nombre d'entrées catégorisées \texttt{normal} et \texttt{attack} dans les jeux de données}
	\label{fig:data_repartition}
\end{figure}

\begin{table}[h]
	\centering
	\begin{tabular}{|l|rrr|}
		\hline
		\textbf{Étiquette} & \textbf{Données totales} & \textbf{Données réseau} & \textbf{Données physiques} \\
		\hline
		normal          & 20 461 956 & 20 453 299 & 8 657 \\
		nomal           & 249        & 0          & 249 \\
		\hline
		\textbf{Total normales} & \textbf{20 462 205} & \textbf{20 453 299} & \textbf{8 906} \\
		\hline
		DoS             & 5 671 852  & 5 671 542  & 310 \\
		MITM            & 2 156 417  & 2 155 409  & 1 008 \\
		physical fault  & 1 549 189  & 1 548 504  & 685 \\
		anomaly         & 389        & 389        & 0 \\
		scan            & 75         & 61         & 14 \\
		\hline
		\textbf{Total attaques} & \textbf{9 377 922}  & \textbf{9 375 905}  & \textbf{2 017} \\
		\hline
		\textbf{TOTAL} & \textbf{29 840 127} & \textbf{29 829 204} & \textbf{10 923} \\
		\hline
	\end{tabular}
	\caption{Répartition des données par label}
	\label{tab:labels_repartition}
\end{table}

On constate qu'il y a beaucoup moins de données physiques que réseau (10 923 contre 29 829 204), ce qui est logique étant donné que les mesures physiques sont prises toutes les secondes, tandis que les relevés réseau sont probablement effectués à chaque paquet transmis (donc plusieurs par seconde).
En effet, \cite{article_reference} indique que les données réseau ont été capturées à l'aide de \textit{Wireshark}, un outil d'analyse de paquets réseau, ce qui confirme cette hypothèse.

% --- I.1.2 Présentation parallèle des données réseau et physiques ---

\subsubsection{Présentation parallèle des données réseau et physiques}

Les statistiques obtenues sur les données réseaux et physiques sont identiques à celle de \cite{article_reference}.
Ainsi, on peut observer le nombre d'entrées pour chaque fichier de données dans les \hyperref[fig:net_number_entries]{Figure 2} et \hyperref[fig:phys_number_entries]{Figure 3}.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.75\textwidth]{images/article/nb_samples_network.png}
	\caption{Nombre d'entrées par fichier de données réseau d'après \cite{article_reference}}
	\label{fig:net_number_entries}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.75\textwidth]{images/article/nb_samples_physical.png}
	\caption{Nombre d'entrées par fichier de données physiques d'après \cite{article_reference}}
	\label{fig:phys_number_entries}
\end{figure}

Il manque cependant les informations sur les fichiers \texttt{attack\_4.csv} et \texttt{dataset\_att\_4.csv} : on y a relevé respectivement \textbf{5 522 490} et \textbf{1 717} entrées, ce qui reste dans la même ordre de grandeur que les autres fichiers d'attaques pour chaque type.

Par ailleurs, on constate dans les deux cas que comparé au fichier dit "normal", les fichiers d'attaques sont plus petits lorsque pris indépendamment.
Cela est expliqué dans \cite{article_reference} par le fait que les périodes d'attaques sont plus courtes que la périodes normale qui a été relevée :

\begin{table}[H]
	\centering
	\resizebox{\textwidth}{!}{%
	\begin{tabular}{|l}
		\textit{Specifically, the first acquisition lasts 1 hour and shows a total of 12 process cycles: it} \\
		\textit{refers to the WDT while working in normal conditions without any attack. On the} \\
		\textit{contrary, the remaining three acquisitions, which last 60 minutes, provide 8, 7 and 4} \\
		\textit{process cycles respectively.}
	\end{tabular}
	}
	\label{tab:quote}
\end{table}

On dispose également de statistiques sur la répartition des différents types d'attaques dans les données, présentées dans les \hyperref[fig:labels_network]{Figure 4} et \hyperref[fig:labels_physical]{Figure 5}.

\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{images/labels_network.png}
	\caption{Répartition des types d'attaques dans les données réseau}
	\label{fig:labels_network}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{images/labels_physical.png}
	\caption{Répartition des types d'attaques dans les données physiques}
	\label{fig:labels_physical}
\end{figure}

On voit que certains types d'attaques sont très représentés, notamment \texttt{DoS} et \texttt{MITM}, tandis que d'autres sont très peu présents, comme \texttt{scan} dans les deux types de données.
Il est donc important de prendre en compte cette répartition lors de l'entraînement des modèles, afin d'éviter qu'ils ne soient biaisés en faveur des classes majoritaires.
Il est probable que les classes \texttt{scan} et \texttt{anomaly} soient également très dificiles à cerner par les modèles.\\

Aussi, le contenu des différentes colonnes est détaillé dans \cite{article_reference}.
Les données récupérées via \textit{Wireshark} en comportent \textbf{14}, listées dans la \hyperref[tab:network_features]{Table 3} (une traduction du tableau original présent dans \cite{article_reference}).\\

\begin{table}[H]
	\centering
	\resizebox{\textwidth}{!}{%
	\begin{tabular}{|c|l|l|}
		\hline
		\textbf{N°} & \textbf{Nom} & \textbf{Description} \\ \hline
		1  & \texttt{Time} & Date d'acquisition \\ \hline
		2  & \texttt{Src IP address} & Adresse IP source \\ \hline
		3  & \texttt{Dst IP adress} & Adresse IP destination \\ \hline
		4  & \texttt{Src MAC address} & Adresse MAC source \\ \hline
		5  & \texttt{Dst MAC address} & Adresse MAC destination \\ \hline
		6  & \texttt{Src Port} & Port source \\ \hline
		7  & \texttt{Dst Port} & Port destination \\ \hline
		8  & \texttt{Proto} & Protocole \\ \hline
		9  & \texttt{TCP flags} & CWR | ECN | URG | ACK | PSH | RST | SYN | FIN flags \\ \hline
		10 & \texttt{Payload size} & Taille de la charge utile \\ \hline
		11 & \texttt{MODBUS code} & Code de fonction MODBUS \\ \hline
		12 & \texttt{MODBUS value} & Valeur réponse MODBUS \\ \hline
		13 & \texttt{num\_pkts\_src} & Nombre de paquets de la même addresse source durant les 2 dernières secondes \\ \hline
		14 & \texttt{num\_pkts\_dst} & Nombre de paquets de la même addresse destination durant les 2 dernières secondes \\ \hline
	\end{tabular}
	}
	\caption{Caractéristiques des données réseau}
	\label{tab:network_features}
\end{table}

Les mesures physiques, quant à elles, concernent des paramètres tels que l'état des pompes, les valeurs de différents capteurs, etc.
En tout, il y en a \textbf{41}, présentées dans la \hyperref[tab:physical_features]{Table 4} (également une traduction du tableau original présent dans \cite{article_reference}).\\

\begin{table}[h!]
	\centering
	\begin{tabular}{|c|l|l|}
		\hline
		\textbf{N°} & \textbf{Nom} & \textbf{Description} \\ \hline
		1  & Time & Date d'acquisition \\ \hline
		2-9  & Tank\_i & Valeur du capteur de presion du réservoir i (i allant de 1 à 8) \\ \hline
		10-15  & Pump\_i & État de la pompe i (i allant de 1 à 6) \\ \hline
		16-19  & Flow\_sensor\_i & Valeur du capteur de débit i (i allant de 1 à 4) \\ \hline
		20-41  & Valv\_i & État de l'électrovanne i (i allant de 1 à 22) \\ \hline
	\end{tabular}
	\caption{Caractéristiques des données physiques}
	\label{tab:physical_features}
\end{table}

\subsubsection{Valeurs manquantes}
\label{sec:missing_values}

Bien entendu, une vérification a été faite pour détecter la présence de valeurs manquantes dans les données.
En l'occurence, les données physiques ne présentent pas de valeurs manquantes.
Concernant les données réseau, elles sont présentées dans la \hyperref[fig:missing_values]{Figure 6} :

\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{images/missing_values.png}
	\caption{Pourcentage de valeurs manquantes par colonne dans les données réseau}
	\label{fig:missing_values}
\end{figure}

% ------------ I.2 Pré-traitement des données -------------

\subsection{Pré-traitement}
\label{label:preprocessing}

L'ensemble des données est soumis a un pré-traitement général avant d'être utilisé par les différents modèles :

\begin{enumerate}
	\item Les données brutes (physique et réseau) sont chargées depuis les différents fichiers CSV.
	\item Les jeux de données étant particulièrement lourds, ils sont sous-échantillonnés pour permettre de travailler sur des sous-ensembles réduits.
	\item Les caractéristiques et les labels sont extraits.
	\item Les valeurs manquantes (cf. \hyperref[sec:missing_values]{1.1.3 Valeurs manquantes}) sont remplacés par des 0.
	\item Les labels sont encodés avec \texttt{LabelEncoder} de \texttt{scikit-learn} \cite{scikit-learn}, ce qui permet de convertir les étiquettes textuelles en valeurs numériques.
	\item Les données sont stratifiées en ensembles d'entraînement, de validation et de test avec \texttt{train\_test\_split} de \texttt{scikit-learn}, en utilisant les options de \texttt{stratify} et \texttt{shuffle} pour garantir une répartition équilibrée des classes dans chaque ensemble.
		  Le ratio utilisé est de 70\% pour l'ensemble d'entraînement, 15\% pour l'ensemble de validation et 15\% pour l'ensemble de test.
	\item Si le \textit{balancing} est activé, il est appliqué sur l'ensemble d'entraînement à l'aide de la fonction \texttt{RandomOverSampler} de la bibliothèque \texttt{imbalanced-learn} \cite{imbalanced-learn}.
	\item Enfin, les données sont normalisées avec \texttt{StandardScaler} de \texttt{scikit-learn} pour garantir que chaque caractéristique ait une moyenne nulle et une variance unitaire.
\end{enumerate}

% ------------ II. Application des algorithmes ------------

\section{Application des algorithmes}

% --------------- II.1 Algorithmes utilisés ---------------

\subsection{Algorithmes utilisés}

	Au total, 7 algorithmes différents ont été implémentés pour ce projet.
	Pour quatre d'entre eux, trois tailles de modèles ont été testées : \texttt{small}, \texttt{medium} et \texttt{large} ; les autres n'ont été testés qu'en taille \texttt{small} et \texttt{medium}.
	Cela sera expliqué plus en détail dans la section \hyperref[sec:hyperparameters]{2.3 Hyperparamètres et résultats}.

Parmi les modèles demandés, les suivants ont été implémentés :
\begin{itemize}
    \item \textbf{KNN} (en \texttt{small}, \texttt{medium} et \texttt{large})
    \item \textbf{Random Forest} (en \texttt{small},  \texttt{medium} et \texttt{large})
    \item \textbf{XGBoost} (en \texttt{small} et \texttt{medium})
    \item \textbf{MLP} (en \texttt{small}, \texttt{medium} et \texttt{large})
\end{itemize}

Le modèle CART n'a pas été implémenté, mais a été remplacé par les trois modèles ci-dessous :

\begin{itemize}
	\item \textbf{Tab Transformer} (en \texttt{small} et \texttt{medium}) : modèle basé sur des transformeurs appliqués aux données tabulaires, utilisant des embeddings pour les variables catégorielles et un mécanisme d’auto-attention pour capturer les interactions entre les caractéristiques.
	\item \textbf{FT Transformer} (en \texttt{small} et \texttt{medium}) : variante optimisée du transformeur pour données tabulaires, combinant embeddings de caractéristiques et couches d’auto-attention avec une tête de prédiction dédiée, offrant de bonnes performances tout en restant peu coûteuse en calcul.
	\item \textbf{MLP avec attention} (en \texttt{small}, en \texttt{medium} et \texttt{large}) : même architecture que le MLP classique, mais avec un mécanisme d'attention ajouté.
\end{itemize}

% ---------- II.2 Organisation des entraînements ----------

\subsection{Organisation des entraînements}

L'ensemble du code est organisé pour permettre une expérimentation facile et reproductible des différents modèles sur les deux types de données.

Les données sont pré-traitées de manière cohérente pour tous les modèles (voir \hyperref[label:preprocessing]{1.2 Pré-traitement}), et un système de cache est mis en place pour éviter de répéter le pré-traitement lors de nouvelles exécutions.
Il est enregistré dans le dossier \texttt{cached\_datasets}.

Chaque modèle est défini dans un script séparé contenu dans un dossier \texttt{models/}, avec des configurations spécifiques (\texttt{configs/model\_type/config\_name.yaml}) pour chaque type de modèle : hyperparamètres, jeux de données, taille des modèles, etc.
Les scripts d'entraînement et de test sont situés dans les fichiers \texttt{scripts/train.py} et \texttt{scripts/test.} \texttt{py}.
Les différents modèles sont entraînés individuellement avec leur script d'entraînement et leur fichier de configuration, ou bien plusieurs modèles peuvent être entraînés simultanément avec le script \texttt{scripts/train\_all.py}.

Les résultats de chaque entraînement sont enregistrés de manière structurée dans le dossier \texttt{experiments} en fonction de leur configuration, permettant une analyse et une comparaison faciles des performances des modèles.
Le détail des résultats enregistrés est présenté dans la section suivante.

% ----------- II.3 Hyperparamètres et résultats -----------

\subsection{Hyperparamères et résultats}
\label{sec:hyperparameters}

En termes d'hyperparamètres, il n'y en a qu'un seul qui a été vraiment manipulé : la taille des modèles utilisés.
En effet, pour chaque type de modèle implémenté, deux ou trois tailles de modèles ont été testées : \texttt{small}, \texttt{medium} et parfois \texttt{large}.
La différence principale entre elles réside dans le nombre de couches et de neurones utilisés et le nombre de données utilisées pour l'apprentissage (il faut \textit{scaler} avec la taille du modèle).
Cependant, étant donné la taille réduite du dataset physique, on utilisera toujours toutes ses données alors qu'on \textit{scalera} sur le réseau.
Par exemple, pour le MLP, le modèle \texttt{small} utilise 2 couches cachées avec 32 et 64 neurones et est entraîné sur 300 000 données réseau, tandis que le modèle \texttt{medium} utilise 3 couches cachées de 64, 128 et 256 neurones et est entraîné sur 500 000 données réseau.\\

Concernant les résultats, sont enregistrés :

\begin{itemize}
	\item les poids du meilleur modèle,
	\item la configuration utilisée (au cas où les configurations changent),
	\item Les métriques sur les jeux de données d'entraînement, validation et test du meilleur modèle,
	\item Les erreurs sur les jeux de données d'entraînement, validation et test du meilleur modèle,
	\item Les courbes de loss et d'accuracy sur les jeux de donnée d'entraînement et de validation.
\end{itemize}

Deux rapports récapitulatifs de tous les entraînements sont ensuite générés avec le script \texttt{src/analyze\_results.py}, un pour les jeux de données physiques \texttt{results\_analysis/physical/report.md} et un pour les jeux de données réseaux \texttt{results\_analysis/network/report.md}.
On y trouve :

\begin{itemize}
	\item un tableau comparatif des performances de chaque modèle, ordonné par F1-score (macro) décroissant,
	\item un tableau récapitulatif des classes mal classées par chaque modèle, ordonné par taux d'erreur décroissant,
	\item un tableau récapitulatif du top 20 des entrées les moins bien classées sur l'ensemble des modèles, avec la prédiction majoritaire,
	\item une matrice de corrélation des erreurs entre les différents modèles,
	\item l'ensemble des courbes d'entraînement pour tous les modèles.
\end{itemize}

% -------------------- III. Résultats ---------------------

\section{Évaluation et comparaison avec les données de référence}

% ------- III.1 Indicateurs et résultats principaux -------

\subsection{Indicateurs et résultats principaux}

% -------------------- III.1.1 Network --------------------

\subsubsection{Pour le jeu de données réseau}

\begin{table}[H]
    \centering
	\resizebox{\textwidth}{!}{%
    \begin{tabular}{c l c c c c c}
    	\hline
    	\textbf{Rang} & \textbf{Modèle} & \textbf{Précision} & \textbf{F1 (macro)} & \textbf{Précision équilibrée} & \textbf{MCC} & \textbf{Temps (s)} \\
    	\hline
			1	& \texttt{small\_random\_forest} 	& 0.8760 & 0.8688 & 0.9592 & 0.5627 & 43.0		\\
			2	& \texttt{small\_knn} 				& 0.8990 & 0.8368 & 0.8442 & 0.3495 & 5.3 		\\
			3	& \texttt{small\_ft\_transformer} 	& 0.8552 & 0.7743 & 0.9598 & 0.5401 & 2673.9 	\\
			4	& \texttt{small\_mlp} 				& 0.8510 & 0.7718 & 0.9585 & 0.5333 & 745.1 	\\
			5	& \texttt{large\_random\_forest} 	& 0.7854 & 0.7490 & 0.9382 & 0.6018 & 744.8 	\\
			6	& \texttt{large\_xgboost} 			& 0.7786 & 0.7456 & 0.9377 & 0.5965 & 364.1 	\\
			7	& \texttt{small\_tab\_transformer} 	& 0.4656 & 0.7042 & 0.8548 & 0.2300 & 2786.7 	\\
			8	& \texttt{medium\_xgboost} 			& 0.7113 & 0.6961 & 0.9279 & 0.4693 & 680.7 	\\
			9	& \texttt{medium\_xgboost} 			& 0.7113 & 0.6961 & 0.9279 & 0.4693 & 381.5 	\\
			10	& \texttt{medium\_random\_forest} 	& 0.7058 & 0.6843 & 0.8724 & 0.4665 & 641.2 	\\
			11	& \texttt{medium\_random\_forest} 	& 0.7058 & 0.6843 & 0.8724 & 0.4665 & 756.0 	\\
			12	& \texttt{large\_knn} 				& 0.8708 & 0.6672 & 0.6907 & 0.5412 & 4.3 		\\
			13	& \texttt{small\_xgboost} 			& 0.8663 & 0.6134 & 0.7095 & 0.5515 & 26.5 		\\
			14	& \texttt{small\_attention\_mlp} 	& 0.6476 & 0.5953 & 0.8121 & 0.1380 & 1308.3 	\\
			15	& \texttt{medium\_knn} 				& 0.8589 & 0.5909 & 0.5706 & 0.2198 & 18.4 		\\
			16	& \texttt{medium\_knn}				& 0.8589 & 0.5909 & 0.5706 & 0.2198 & 17.3 		\\
			17	& \texttt{medium\_attention\_mlp} 	& 0.7089 & 0.5452 & 0.7450 & 0.4650 & 161.1 	\\
			18	& \texttt{large\_attention\_mlp} 	& 0.7700 & 0.4577 & 0.6085 & 0.5831 & 2889.7 	\\
			19	& \texttt{medium\_mlp} 				& 0.6955 & 0.4523 & 0.7653 & 0.4563 & 24.8 		\\
			20	& \texttt{medium\_ft\_transformer} 	& 0.7108 & 0.4457 & 0.6015 & 0.4658 & 385.7 	\\
			21	& \texttt{medium\_tab\_transformer}	& 0.8820 & 0.3215 & 0.3307 & 0.1420 & 268.6 	\\
			22	& \texttt{large\_mlp} 				& 0.4899 & 0.2944 & 0.4081 & 0.3221 & 2994.4 	\\
    	\hline
    \end{tabular}
	}
	\caption{Comparaison des expériences sur le jeu de données network}
    \label{tab:network_results}
\end{table}

\begin{table}[H]
	\centering
	\begin{tabular}{lcccc}
		\hline
		\textbf{Algorithme} & \textbf{Exactitude} & \textbf{Rappel} & \textbf{Précision} & \textbf{F1-score}\\
		\hline
		KNN & 0,77 & 0.44 & 0,68 & 0,53\\
		RF  & 0,75 & 0,53 & 0,56 & 0,54\\
		SVM & 0,69 & 0,99 & 0,10 & 0,20\\
		NB  & 0,75 & 0,15 & 0,90 & 0,27\\
		\hline
	\end{tabular}
	\caption{Résultats de l’évaluation des algorithmes d’apprentissage automatique sur le jeu de données physique}
	\label{tab:article_res_net}
\end{table}

% -------------------- III.1.2 Physical -------------------

\subsubsection{Pour le jeu de données physiques}

D'après les résultats présentés dans la \hyperref[tab:physical_results]{Table 5}, le modèle \texttt{large\_xgboost} obtient les meilleures performances sur le jeu de données \texttt{physical}, avec une précision de \textbf{98,60\%}, un F1-macro de \textbf{0,8179}, une précision équilibrée de \textbf{0,8174} et un MCC de \textbf{0,9609}.
Le temps d'entraînement est également très faible (quelques secondes), ce qui en fait un choix efficace pour ce type de données.
À l'inverse, les modèles \texttt{small\_random\_forest} ou \texttt{large\_ft\_transformer} affichent les performances les plus faibles, ce qui peut s'expliquer par un manque de capacité de généralisation pour le premier (sous-apprentissage dû à une structure trop restreinte) et une difficulté de convergence ou un sur-ajustement (overfitting) pour le second, les architectures de type Transformer étant souvent plus complexes à optimiser sur des données tabulaires de taille réduite.

\begin{table}[H]
    \centering
	\resizebox{\textwidth}{!}{%
    \begin{tabular}{c l c c c c c}
    	\hline
    	\textbf{Rang} & \textbf{Modèle} & \textbf{Précision} & \textbf{F1 (macro)} & \textbf{Précision équilibrée} & \textbf{MCC} & \textbf{Temps (s)} \\
    	\hline
			1	& \texttt{large\_xgboost} 				& 0.9860 & 0.8179 & 0.8174 & 0.9609 & 3.9 	\\
			2	& \texttt{medium\_xgboost}				& 0.9872 & 0.8134 & 0.8075 & 0.9641 & 3.1 	\\
			3	& \texttt{large\_random\_forest} 		& 0.9866 & 0.8132 & 0.8001 & 0.9622 & 0.9 	\\
			4	& \texttt{medium\_tab\_transformer}		& 0.9780 & 0.8129 & 0.8270 & 0.9419 & 249.2 \\
			5	& \texttt{medium\_knn} 					& 0.9793 & 0.8095 & 0.8249 & 0.9450 & 0.0 	\\
			6	& \texttt{small\_k5\_dist\_knn} 			& 0.9793 & 0.8095 & 0.8249 & 0.9450 & 0.0 	\\
			7	& \texttt{medium\_knn} 					& 0.9793 & 0.8095 & 0.8249 & 0.9450 & 0.0 	\\
			8	& \texttt{large\_knn} 					& 0.9823 & 0.8053 & 0.8079 & 0.9505 & 0.0 	\\
			9	& \texttt{small\_knn} 					& 0.9774 & 0.8007 & 0.8235 & 0.9402 & 0.0 	\\
			10	& \texttt{small\_tab\_transformer} 		& 0.9683 & 0.8001 & 0.8250 & 0.9188 & 40.7 	\\
			11	& \texttt{medium\_random\_forest} 		& 0.9695 & 0.7936 & 0.8150 & 0.9198 & 0.6 	\\
			12	& \texttt{medium\_attention\_mlp} 		& 0.9365 & 0.7612 & 0.8163 & 0.8510 & 108.1 \\
			13	& \texttt{small\_k10\_manhattan\_knn} 	& 0.9390 & 0.7531 & 0.8164 & 0.8564 & 0.0 	\\
			14	& \texttt{large\_tab\_transformer} 		& 0.9475 & 0.7352 & 0.7068 & 0.8504 & 66.5 	\\
			15	& \texttt{small\_attention\_mlp} 		& 0.9048 & 0.7259 & 0.8106 & 0.7946 & 35.2 	\\
			16	& \texttt{medium\_ft\_transformer} 		& 0.9042 & 0.7178 & 0.7954 & 0.7806 & 126.6 \\
			17	& \texttt{medium\_attention\_mlp} 		& 0.8969 & 0.7129 & 0.8080 & 0.7809 & 62.3 	\\
			18	& \texttt{medium\_ft\_transformer} 		& 0.8847 & 0.6974 & 0.7991 & 0.7601 & 121.0 \\
			19	& \texttt{small\_k20\_uniform\_knn} 	& 0.8908 & 0.6969 & 0.8062 & 0.7722 & 0.0 	\\
			20	& \texttt{small\_mlp} 					& 0.8786 & 0.6889 & 0.7988 & 0.7515 & 22.7 	\\
			21	& \texttt{medium\_mlp} 					& 0.8700 & 0.6864 & 0.7902 & 0.7397 & 49.3 	\\
			22	& \texttt{small\_ft\_transformer} 		& 0.8401 & 0.6593 & 0.7970 & 0.7004 & 56.1 	\\
			23	& \texttt{small\_xgboost} 				& 0.8676 & 0.6412 & 0.7906 & 0.7287 & 0.6 	\\
			24	& \texttt{large\_mlp} 					& 0.7724 & 0.5396 & 0.7633 & 0.6137 & 20.9	\\
			25	& \texttt{large\_attention\_mlp} 		& 0.6949 & 0.4734 & 0.7326 & 0.5333 & 13.1 	\\
			26	& \texttt{small\_random\_forest} 		& 0.6101 & 0.4687 & 0.7242 & 0.4779 & 0.2 	\\
			27	& \texttt{large\_ft\_transformer} 		& 0.6992 & 0.4644 & 0.6359 & 0.5176 & 82.2 	\\
    	\hline
    \end{tabular}
	}
	\caption{Comparaison des expériences sur le jeu de données physiques}
    \label{tab:physical_results}
\end{table}

En comparant les résultats obtenus avec ceux de l'article de référence \cite{article_reference}, on constate que nos modèles affichent des performances globales très compétitives en termes d'exactitude (accuracy), bien que le F1-score macro suggère une difficulté persistante à classifier parfaitement certaines classes minoritaires par rapport aux résultats de l'article.
En effet dans la \hyperref[tab:results_physical]{Table 6}, on peut voir que les performances des KNN, Random Forest, SVM et Naive Bayes (NB) sont sensiblement supérieures aux nôtres en termes de F1-score. Cette différence peut provenir d'un prétraitement des données distinct, d'une gestion différente du déséquilibre des classes, ou de l'utilisation d'une moyenne pondérée (weighted) plutôt que macro pour le calcul du F1-score dans l'article de référence.

\begin{table}[H]
	\centering
	\begin{tabular}{lcccc}
		\hline
		\textbf{Algorithme} & \textbf{Exactitude} & \textbf{Rappel} & \textbf{Précision} & \textbf{F1-score}\\
		\hline
		KNN & 0,98 & 0.95 & 0,95 & 0,95\\
		RF  & 0,99 & 0,98 & 0,95 & 0,97\\
		SVM & 0,93 & 0,92 & 0,64 & 0,75\\
		NB  & 0,93 & 0,92 & 0,66 & 0,77\\
		\hline
	\end{tabular}
	\caption{Résultats de l’évaluation des algorithmes d’apprentissage automatique sur le jeu de données physique}
	\label{tab:article_res_phy}
\end{table}

% --------------- III.3 Analyse des erreurs ---------------

\subsection{Analyse des erreurs}

En s'attardant sur les erreurs commises par les différents modèles, on peut observer certaines corrélation entre celles-ci, comme le montre les \hyperref[fig:corrmat_network]{Figure 6} et \hyperref[fig:corrmat_physical]{Figure 7}.
Par exemple — et sans surprise — le modèle MLP et le modèle MLP avec attention présentent une forte corrélation dans leurs erreurs.

\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{images/correlation_heatmap/network.png}
	\caption{Matrice de corrélation des erreurs entre les modèles pour les données réseau}
	\label{fig:corrmat_network}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{images/correlation_heatmap/physical.png}
	\caption{Matrice de corrélation des erreurs entre les modèles pour les données physiques}
	\label{fig:corrmat_physical}
\end{figure}

Comme il y a très peu de faible corrélations, il est raisonnable de penser que certains échantillons sont systématiquement mal classés par tous les modèles.
La \hyperref[tab:misclassified_samples_physical]{Table 6} liste les échantillons qui ont été mal classés par l'ensemble des modèles lors de nos différentes exécutions, ainsi que la prédiction majoritaire effectuée par les modèles pour ces échantillons.
Heureusement, on constate que leur nombre est très faible — seulement 17 échantillons sur un total de X — donc il n'y a pas beaucoup d'entrées réellement problématiques.

On remarque que la majorité des échantillons mal classés appartiennent à la classe \texttt{normal}, ce qui indique que les modèles ont du mal à distinguer les échantillons normaux des anomalies dans certains cas.
Cela peut s'expliquer par le fait que les mesures sont effectuées toutes les secondes, et donc la limite entre un état normal et un état anormal peut être très fine.
Il y a également des des échantillons mal classés appartenant à la classe \texttt{scan} qui est sous-représentée, ce qui peut expliquer les difficultés rencontrées par les modèles pour les classer correctement.
De même, l'étiquiette \texttt{scan} est plusieurs fois prédite de manière erronée, ce qui montre bien que les modèles ont du mal à savoir à quoi correspond cette classe.

\begin{table}[H]
	\centering
	\begin{tabular}{c l c l}
		\hline
		\textbf{Entrée} & \textbf{Label réel} & \textbf{Nombre d'erreurs} & \textbf{Prédiction majoritaire} \\
		\hline
		36   & scan   & 10 & normal \\
		768  & normal & 10 & physical fault \\
		848  & normal & 10 & physical fault \\
		927  & normal & 10 & MITM \\
		1257 & normal & 10 & physical fault \\
		1549 & scan   & 10 & normal \\
		\hline
	\end{tabular}
	\caption{Échantillons physiques systématiquement mal classés lors des différentes exécutions}
	\label{tab:misclassified_samples_physical}
\end{table}

% TO MODIFY
\begin{table}[H]
	\centering
	\begin{tabular}{c l c l}
		\hline
		\textbf{Entrée} & \textbf{Label réel} & \textbf{Nombre d'erreurs} & \textbf{Prédiction majoritaire} \\
		\hline
		TO COMPLETE & TO COMPLETE & TO COMPLETE & TO COMPLETE \\
		\hline
	\end{tabular}
	\caption{20 échantillons réseau systématiquement mal classés lors des différentes exécutions}
	\label{tab:misclassified_network}
\end{table}

\section*{Conclusion}
\addcontentsline{toc}{section}{Conclusion}

\newpage

\printbibliography[heading=bibintoc, title={Références}]

\newpage

\section*{Retour personnel : CERISARA Nathan}

\subsection*{Contribution}

Dans ce pojet, j'ai principalement travaillé à développer l'architecture modulaire dont je suis très fier pour l'entraînement et le test des modèles, et le script qui va automatiquement analyser les résultats et les afficher dans un rapport markdown et les mettre à disposition de l'app streamlit.
J'ai entraîné les modèles sur mon ordinateur fixe (Ryzen 5 3600, 24 Go de RAM, GTX Titan X) et j'ai surveillé les entraînements et modifié certaines configurations pour faire que certains modèles apprennent mieux et réduire l'overfitting.

\subsection*{Avis}

J'ai pas appris grand chose avec ce projet, je savais déjà analyser / traiter des données, et je savais déjà mettre en place une pipeline d'entraînement de modèles.
Si on avait eu le temps (pas eu à faire 7 projets en même temps dont 2 très gros et très importants), j'aurais peut-être pu aller plus loin dans le concept de prédiction d'attaque et de détection d'anomalie, et de mettre en place des méthodes que l'on n'utilise que dans ces domaines, mais je n'ai donc pas eu le temps de regarder cela.

\newpage

\section*{Retour personnel : DESBERG Clément}

\subsection*{Contribution}

Je me suis occupé exclusivement de la partie streamlit.
Je n'ai absolument pas l'habitude de présenter des données sous la forme d'une application web, je trouvais donc cette partie particulièrement intéressante.
J'ai demandé à mes camarades de me donner des fonctions dont les résultats seraient les données à afficher dans un fichier python précis (qui faisait en quelque sorte office d'API interne).
À partir des deux fonctions de récupération des données, j'ai donc réalisé l'application streamlit, en prenant soit d'exclure toutes les informations fournies qui ne me semblaient pas pertinentes voir préjudiciables, et en intégrant les autres données de manière intelligibles.

\subsection*{Avis}

Bien que je n'ai pas écrit le code des tests des modèles ou de nettoyage des données d'entrée, j'ai quand même appris un certain nombre de choses, d'abord sur streamlit en lui-même, mais aussi sur la manière dont on pouvait présenter les résultats d'un tel projet autrement que dans un rapport (je n'avais jamais ne serait-ce qu'entendu parler de streamlit avant ce projet).
J'ai beaucoup aimé streamlit et la manière de l'utiliser pour présenter notre projet, c'est agréable à utiliser, très user-friendly (le fait de pouvoir afficher directement un nombre assez grand de types de données différents, et le support des icônes rondes de google pour les menus), et très pratique en terme de développement pur (le fait de ne pas avoir à relancer l'app à chaque modification, au prix d'un recalcul complet des graphiques à chaque rechargement de la page ou chaque bouton cliqué).
Je n'ai pas de point négatif à soulever par rapport à ce projet.

\newpage

\section*{Retour personnel : JACQUET Ysée}

\subsection*{Contribution}

Il faut bien au moins une personne pour le rapport, et c'est moi.
Installation Latex (parce qu'Overleaf ne permet pas de travailler à plus que 2), rédaction, mise en forme...
Pour être honnête, j'aurais aussi aimé faire de l'analyse de données (généralement la partie que je préfère) mais les données prenaient une place trop conséquente pour mon ordinateur.
La découverte de Streamlit m'intéressait également, mais Clément s'en est très bien occupé (et je maîtrisais Latex, pas lui).
Donc c'était une question d'optimisation de l'efficacité du groupe, je dirais.

\subsection*{Avis}

C'est typiquement mon genre de projet préféré, dommage qu'il tombe au milieu d'une période chargée (mes camarades en parlent suffisamment dans leur paragraphe).
Je pense que l'analyse, dans le sens l'explication, des données et des résultats auraient pu être plus poussés avec plus de temps.
Je notifierai juste de penser aux ordinateurs qui n'ont plus beaucoup de place (10Go de données, c'est peut-être un peu too much pour du scolaire).
En tout cas je pars du principe que si le projet n'est pas fait sur des heures de cours, alors on doit pouvoir le réaliser sur notre ordinateur personnel, ce qui veut dire pas nécessairement beaucoup de place ou de puissance.

\newpage

\section*{Retour personnel : LEVY Lucas}

\subsection*{Contribution}

Dans ce projet, j’ai fait une première analyse sur le fichier Network pour faire une vérification des labels et des colonnes de \texttt{attack\_1.csv}, à la fois pour les distributions et le nombre de vides selon les colonnes.
J’ai ensuite développé un premier random forest sur les données network pour obtenir un premier jet de modèle.
J’ai complété l’analyse en la déployant sur tous les fichiers Network et j'ai étendu l’analyse aux fichiers Physical afin de la rendre globale.
J’ai rajouté des choses dans l’analyse qui permettent d’obtenir de nouvelles distributions comme par exemple la distribution des protocoles par labels.
Enfin, j’ai exporté les résultats de l’analyse en \texttt{JSON} pour l’affichage streamlit et en \texttt{TXT} pour un visuel plus simple et pour aider le transfert vers streamlit qui n’a pas été utilisé pour cela mais ça m'a aussi permis de mieux vérifier les erreurs.

\subsection*{Avis}

J’ai peu appris de choses nouvelles lors de ce projet en tant que compétence technique, cependant, j’ai bien aimé l’analyse des données car les données sont vraiment réelles et on doit contourner un certain nombre de problèmes humains qui se retrouvent dans un vrai dataset.
Je suis content du résultat mais probablement que j'aurais pu aller plus loin ou être plus propre si le nombre de projets en parallèle de celui-ci n'était pas aussi grand. 

\end{document}