\documentclass{rapport}

\usepackage{subcaption}
\usepackage{blindtext}
\usepackage{lipsum}
\usepackage{enumitem}
\usepackage{setspace}
\usepackage{eurosym}
\usepackage{adjustbox}
\usepackage{changepage}
\usepackage{booktabs}

% \usepackage{breakurl}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{minted}
\usepackage{fontawesome}

\usepackage{booktabs}
\usepackage[table]{xcolor}

\definecolor{LightGray}{gray}{0.95}
\definecolor{pale_red}{HTML}{F4A7A3}
\definecolor{pale_green}{HTML}{E8F5DC}
\definecolor{pale_violet}{HTML}{E7D8F5}
\definecolor{pale_yellow}{HTML}{F8E68C}
\definecolor{pale_blue}{HTML}{97DAD9}

\usepackage{tikz}
\newcommand{\colorboxsquare}[1]{\tikz \fill[#1] (0,0) rectangle (0.3,0.3);}

\usepackage{csquotes}
\usepackage{biblatex}
\addbibresource{biblio.bib}
\setlength{\bibitemsep}{\itemsep}
\setlength{\bibparsep}{\parsep}

\newcommand{\ttt}[1]{\texttt{#1}}

\newcommand{\myparagraph}[1]{%
  	\paragraph{#1} \mbox{} \\
  	\vspace{-1em}
}

\setlist[itemize,1]{label={\textbullet}}
\setlist[itemize,2]{label={$\blacktriangleright$}}


\title{Rapport de protection des données} % Titre du fichier

\onehalfspacing

\begin{document}


%----------- Informations du rapport ---------

\setlogo{images/LogoTPS.png} % Définit le logo
\setunif{Télécom Physique Strasbourg}
\setsujet{Rapport de protection des données}
\settitre{Analyse de données cyberphysiques sur la distribution d'eau}
\seteleves{Nathan \textsc{Cerisara}\\Clément \textsc{Desberg}\\Ysée \textsc{Jacquet}\\Lucas \textsc{Levy}} %Nom des élèves

%----------- Initialisation -------------------

\fairepagedegarde
\fairemarges

\newpage

\tabledematieres
\listoffigures

\section*{Abréviations employées}

\begin{itemize}
	\item \textbf{CART} : Classification And Regression Trees
    \item \textbf{CNN} : Convolutional Neural Network
	\item \textbf{CSV} : Comma Separated Values
	\item \textbf{FT Transformer} : Feature Tokenizer Transformer
	\item \textbf{KNN} : K-Nearest Neighbors
	\item \textbf{MLP} : Multi-Layer Perceptron
	\item \textbf{MCC} : Matthews Correlation Coefficient
	\item \textbf{NLP} : Natural Language Processing
\end{itemize}

% % Table des tableaux (si nécessaire)
% \listoftables

%------------ Corps du rapport ----------------

\newpage
\pagenumbering{arabic} % réactiver la numérotation
\setcounter{page}{1}  % réinitialiser le compteur de pages

\section*{Introduction}

Ce projet consiste en l'analyse de données cyberphysiques issues d'un système de distribution d'eau potable \cite{dataset}.
L'objectif principal est de développer et d'évaluer des modèles de machine learning capables de détecter et de classer les anomalies dans le système, telles que les attaques informatiques ou les défaillances physiques.
Parmi les modèles demandés, K-Nearest Neighbors (KNN), Random Forest, XGBoost et Multi-Layer Perceptron (MLP) ont été implémentés.
De plus, des modèles basés sur des architectures de transformers adaptées aux données tabulaires on été testés en remplacement de l'algorithme de Classification And Regression Trees (CART).
Finalement, les performances des modèles développés ont été comparées avec celles fournies dans l'article de référence \cite{article_reference}.

\section{Données}

L'ensemble des données comprend 5 fichiers Comma Separated Values (CSV) sur les relevés physiques et 5 fichiers CSV sur les relevés réseau.
Dans chaque cas, il y a un fichier de mesures prises en période normale – sans anomalie – et 4 fichiers de mesures prises en période anormale, avec des anomalies correspondant au type de données (attaques informatiques ou défaillances physiques).
Le sujet de chaque fichier est résumé dans la \hyperref[tab:files]{Table 1}.

\begin{table}[h]
	\centering
	\begin{tabular}{|l|l|}
		\hline
		\multicolumn{1}{|c|}{\textbf{Fichier}} & \multicolumn{1}{|c|}{\textbf{Contenu}} \\
		\hline
		\mintinline{text}{normal.csv}  & Acquisitions du traffic réseau en période normale \\
		\hline
		\mintinline{text}{phy_norm.csv}  & Acquisitions des mesures physiques en période normale \\
		\hline
		\mintinline{text}{attack_1.csv}  & Première acquisition du traffic réseau avec anomalies \\
		\hline
		\mintinline{text}{dataset_att_1.csv}  & Première acquisition des mesures physiques avec anomalies \\
		\hline
		\mintinline{text}{attack_2.csv}  & Deuxième acquisition du traffic réseau avec anomalies \\
		\hline
		\mintinline{text}{dataset_att_2.csv}  & Deuxième acquisition des mesures physiques avec anomalies \\
		\hline
		\mintinline{text}{attack_3.csv}  & Troisième acquisition du traffic réseau avec anomalies \\
		\hline
		\mintinline{text}{dataset_att_3.csv}  & Troisième acquisition des mesures physiques avec anomalies \\
		\hline
		\mintinline{text}{attack_4.csv}  & Quatrième acquisition du traffic réseau avec anomalies \\
		\hline
		\mintinline{text}{dataset_att_4.csv}  & Quatrième acquisition des mesures physiques avec anomalies \\
		\hline
	\end{tabular}
	\caption{Aperçu des fichiers de données fournis, d'après le fichier fourni \texttt{README.xlsx}}
	\label{tab:files}
	\end{table}

Il y a également des fichiers packet capture (PCAP) fournis pour les données réseau, mais ceux-ci n'ont pas été utilisés dans le cadre de ce projet.

\subsection{Visualisation des données}

\subsubsection{Présentation générale des données}

Dans chaque fichier CSV, une ligne représente un ensemble de données collectées à un instant donné, tandis que les colonnes renvoient à différents mécanismes sur lesquels une mesure a été faite.

\myparagraph{Données physiques}

Les mesures physiques sont reportées toutes les secondes et concernent des paramètres tels que l'état des pompes, les valeurs de différents capteurs, etc.
En tout, il y a 41 caractéristiques, présentées dans la \hyperref[tab:features]{Table 2} (une traduction du tableau original présent dans \cite{article_reference}).

\begin{table}[h!]
	\centering
	\begin{tabular}{|c|l|l|}
		\hline
		\textbf{N°} & \textbf{Nom} & \textbf{Description} \\ \hline
		1  & Time & Date d'acquisition \\ \hline
		2-9  & Tank_i & Valeur du capteur de presion du réservoir i (i allant de 1 à 8) \\ \hline
		10-15  & Pump_i & État de la pompe i (i allant de 1 à 6) \\ \hline
		16-19  & Flow_sensor_i & Valeur du capteur de débit i (i allant de 1 à 4) \\ \hline
		20-41  & Valv_i & État de l'électrovanne i (i allant de 1 à 22) \\ \hline
	\end{tabular}
	\caption{Caractéristiques des données physiques}
	\label{tab:features}
\end{table}

\myparagraph{Données réseau}

Au nombre de 14, les données réseau sont listées dans la \hyperref[tab:features]{Table 2} (une traduction du tableau original présent dans \cite{article_reference}).

\begin{table}[h!]
	\centering
	\begin{tabular}{|c|l|l|}
		\hline
		\textbf{N°} & \textbf{Nom} & \textbf{Description} \\ \hline
		1  & Time & Date d'acquisition \\ \hline
		2  & Src IP address & Adresse IP source \\ \hline
		3  & Dst IP adress & Adresse IP destination \\ \hline
		4  & Src MAC address & Adresse MAC source \\ \hline
		5  & Dst MAC address & Adresse MAC destination \\ \hline
		6  & Src Port & Port source \\ \hline
		7  & Dst Port & Port destination \\ \hline
		8  & Proto & Protocole \\ \hline
		9  & TCP flags & CWR | ECN | URG | ACK | PSH | RST | SYN | FIN flags \\ \hline
		10 & Payload size & Taille de la charge utile \\ \hline
		11 & MODBUS code & Code MODBUS \\ \hline
		12 & MODBUS value & Valeur réponse MODBUS \\ \hline
		13 & num\_pkts\_src & Nombre de paquets de la même addresse source durant les 2 dernières secondes \\ \hline
		14 & num\_pkts\_dst & Nombre de paquets de la même addresse destination durant les 2 dernières secondes \\ \hline
	\end{tabular}
	\caption{Caractéristiques des données réseau}
	\label{tab:features}
\end{table}
	

\subsubsection{Analyse des données}

\subsection{Prétraitement}

La pipeline actuelle de prétraitement des données est la suivante :

\begin{enumerate}
	\item Charger les données brutes à partir de tous les fichiers CSV du jeu de données sélectionné (\textit{physical} ou \textit{network}).
	\item Sous Echantillonage de l'ensemble des données pour ne pas travailler sur tout le dataset, mais sur un sous ensemble réduit.
	\item Extraction des features et des labels.
	\item Encodage des labels avec \textit{LabelEncoder} de \textit{scikit-learn}.
	\item Stratification de l'ensemble des données en ensembles d'entraînement, de validation et de test avec \textit{train\_test\_split} de \textit{scikit-learn} avec les options de \textit{stratify} et \textit{shuffle} avec un ratio de 70\% - 15\% - 15\% pour l'ensemble d'entraînement, de validation et de test.
	\item Application du balancing sur l'ensemble d'entraînement si activé :
	\begin{itemize}
		\item \textbf{OverSampling} avec \textit{SMOTE}
		\item \textbf{OverSampling} avec \textit{RandomOverSampler}
		\item \textbf{OverSampling} manuellement avec l'augmentation des données
		\item \textbf{UnderSampling} avec \textit{RandomUnderSampler}
		\item \textbf{UnderSampling} avec \textit{KNN for easy data}
	\end{itemize}
	\item Normalisation des données avec \textit{StandardScaler} de \textit{scikit-learn}
\end{enumerate}

\section{Application des algorithmes}

\begin{itemize}
    \item Organisation des modèles bien structurée
    \item Scripts définissant la structure de chaque modèle dans le dossier \texttt{models/}.
	\item Différentes configurations pour chaque modèle (hyperparamètres, datasets, taille des modèles, etc.) dans \texttt{configs/model\_type/config\_name.yaml}.
	\item Scripts d'entraînement et de test dans \texttt{scripts/train.py} et \texttt{scripts/test.py}.
	\item Les données sont pré-traitées en amont \textbf{de la même façon pour tous les types de modèles}.
\end{itemize}

\subsection{KNN}

\subsection{Random Forest}

\subsection{XGBoost}

\subsection{MLP}

\subsection{Modèles de transformers}

\subsubsection{Tab Transformer}

\subsubsection{FT Transformer}

\subsubsection{MLP avec attention}

\section{Évaluation et comparaison avec les données de référence}

\subsection{Données physiques}

D'après les résultats présentés dans la \hyperref[tab:physical_small_results]{Table 3}, le modèle \texttt{small\_knn} obtient les meilleures performances sur le jeu de données \texttt{physical\_small}, avec une précision de \textbf{97,74\%}, un F1-macro de \textbf{0,8007}, une précision équilibrée de \textbf{0,8235} et un MCC de \textbf{0,9402}.
Le temps d'entraînement est également très faible (quasi-instantané), ce qui en fait un choix efficace pour ce type de données.
À l'inverse, le modèle \texttt{small\_random\_forest} affiche les performances les plus faibles, ce qui peut s'expliquer par une répartition des classses TO COMPLETE.

\begin{table}[H]
    \centering
	\resizebox{\textwidth}{!}{%
    \begin{tabular}{c l c c c c c}
    	\hline
    	\textbf{Rang} & \textbf{Modèle} & \textbf{Précision} & \textbf{F1 (macro)} & \textbf{Précision équilibrée} & \textbf{MCC} & \textbf{Temps (s)} \\
    	\hline
    	1 & \texttt{small\_knn} & 0.9774 & 0.8007 & 0.8235 & 0.9402 & 0.0 \\
    	2 & \texttt{small\_tab\_transformer} & 0.9683 & 0.8001 & 0.8250 & 0.9188 & 40.7 \\
    	3 & \texttt{small\_attention\_mlp} & 0.9048 & 0.7259 & 0.8106 & 0.7946 & 35.2 \\
    	4 & \texttt{small\_mlp} & 0.8786 & 0.6889 & 0.7988 & 0.7515 & 22.7 \\
    	5 & \texttt{small\_ft\_transformer} & 0.8401 & 0.6593 & 0.7970 & 0.7004 & 56.1 \\
    	6 & \texttt{small\_xgboost} & 0.8676 & 0.6412 & 0.7906 & 0.7287 & 0.6 \\
    	7 & \texttt{small\_random\_forest} & 0.6101 & 0.4687 & 0.7242 & 0.4779 & 0.2 \\
    	\hline
    \end{tabular}
	}
	\caption{Comparaison des expériences sur le jeu de données physiques physical\_small}
    \label{tab:physical_small_results}
\end{table}

En comparant les résultats obtenus avec ceux de l'article de référence \cite{article_reference}, on constate que nos modèles TO COMPLETE.
En effet dans la \hyperref[tab:results_physical]{Table 4}, on peut voir que les performances des KNN, Random Forest, SVM et Naive Bayes (NB) sont TO COMPLETE.

\begin{table}[ht]
	\centering
	\begin{tabular}{lcccc}
		\hline
		\textbf{Algorithme} & \textbf{Exactitude} & \textbf{Rappel} & \textbf{Précision} & \textbf{F1-score}\\
		\hline
		KNN & 0,98 & 0.95 & 0,95 & 0,95\\
		RF  & 0,99 & 0,98 & 0,95 & 0,97\\
		SVM & 0,93 & 0,92 & 0,64 & 0,75\\
		NB  & 0,93 & 0,92 & 0,66 & 0,77\\
		\hline
	\end{tabular}
	\caption{Résultats de l’évaluation des algorithmes d’apprentissage automatique sur le jeu de données physique}
	\label{tab:results_physical}
\end{table}

En s'attardant sur les erreurs commises par les différents modèles, on peut observer certaines corrélation entre celles-ci, comme le montre la \hyperref[fig:corrmat]{Figure 1}.
Par exemple — et sasns surprise — le modèle MLP et le modèle MLP avec attention présentent une forte corrélation dans leurs erreurs.

\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{images/correlation_heatmap.png}
	\caption{Matrice de corrélation des erreurs entre les modèles}
	\label{fig:corrmat}
\end{figure}

Comme il y a très peu de faible corrélations, il est raisonnable de penser que certains échantillons sont systématiquement mal classés par tous les modèles.
La \hyperref[tab:misclassified_samples]{Table 5} liste les échantillons qui ont été mal classés par l'ensemble des modèles lors de nos différentes exécutions, ainsi que la prédiction majoritaire effectuée par les modèles pour ces échantillons.
Heureusement, on constate que leur nombre est très faible — seulement 17 échantillons sur un total de X — donc il n'y a pas beaucoup d'entrées réellement problématiques.

On remarque que la majorité des échantillons mal classés appartiennent à la classe \texttt{normal}, ce qui indique que les modèles ont du mal à distinguer les échantillons normaux des anomalies dans certains cas.
Cela peut s'expliquer par le fait que les mesures sont effectuées toutes les secondes, et donc la limite entre un état normal et un état anormal peut être très fine.
Il y a également des des échantillons mal classés appartenant à la classe \texttt{scan} qui est sous-représentée, ce qui peut expliquer les difficultés rencontrées par les modèles pour les classer correctement.
De même, l'étiquiette \texttt{scan} est plusieurs fois prédite de manière erronée, ce qui montre bien que les modèles ont du mal à savoir à quoi correspond cette classe.

\begin{table}[H]
	\centering
	\begin{tabular}{c l c l}
		\hline
		\textbf{Entrée} & \textbf{Label réel} & \textbf{Nombre d'erreurs} & \textbf{Prédiction majoritaire} \\
		\hline
		5    & normal & 7 & MITM \\
		35   & normal & 7 & MITM \\
		36   & scan   & 7 & normal \\
		210  & normal & 7 & MITM \\
		466  & normal & 7 & DoS \\
		598  & normal & 7 & scan \\
		768  & normal & 7 & physical fault \\
		848  & normal & 7 & physical fault \\
		864  & normal & 7 & scan \\
		892  & normal & 7 & DoS \\
		927  & normal & 7 & MITM \\
		1104 & normal & 7 & MITM \\
		1203 & normal & 7 & scan \\
		1257 & normal & 7 & physical fault \\
		1549 & scan   & 7 & normal \\
		1559 & normal & 7 & physical fault \\
		1628 & normal & 7 & MITM \\
		\hline
	\end{tabular}
	\caption{Échantillons systématiquement mal classés lors des différentes exécutions}
	\label{tab:misclassified_samples}
\end{table}




\section*{Conclusion}

\newpage

\printbibliography[heading=bibintoc, title={Références}]
\addcontentsline{toc}{section}{Références}

\end{document}