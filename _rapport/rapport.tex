\documentclass{rapport}

%--------------------------------------------------
% Packages de base et mise en forme
%--------------------------------------------------
\usepackage{blindtext}
\usepackage{lipsum}
\usepackage{enumitem}
\usepackage{setspace}
\usepackage{changepage}
\usepackage{adjustbox}

%--------------------------------------------------
% Mathématiques et symboles
%--------------------------------------------------
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{eurosym}

%--------------------------------------------------
% Tableaux et couleurs
%--------------------------------------------------
\usepackage{booktabs}
\usepackage[table]{xcolor}
\usepackage{subcaption}

\definecolor{LightGray}{gray}{0.95}
\definecolor{pale_red}{HTML}{F4A7A3}
\definecolor{pale_green}{HTML}{E8F5DC}
\definecolor{pale_violet}{HTML}{E7D8F5}
\definecolor{pale_yellow}{HTML}{F8E68C}
\definecolor{pale_blue}{HTML}{97DAD9}

%--------------------------------------------------
% Graphiques et TikZ
%--------------------------------------------------
\usepackage{tikz}

\newcommand{\verticalquote}[1]{%
    \begin{tikzpicture}[remember picture, overlay]
        \draw[thick,black] (-0.5cm,0) -- (-0.5cm,-0.4cm);
    \end{tikzpicture}%
    \hspace{0.5cm}\itshape#1}

\newcommand{\colorboxsquare}[1]{%
    \tikz \fill[#1] (0,0) rectangle (0.3,0.3);
}

%--------------------------------------------------
% Code, icônes et typographie
%--------------------------------------------------
\usepackage{minted}
\usepackage{fontawesome}
\usepackage{csquotes}

\newcommand{\ttt}[1]{\texttt{#1}}

%--------------------------------------------------
% Bibliographie
%--------------------------------------------------
\usepackage[
    backend=biber,
    style=numeric,
    sorting=none
]{biblatex}

\addbibresource{biblio.bib}

\setlength{\bibitemsep}{\itemsep}
\setlength{\bibparsep}{\parsep}

%--------------------------------------------------
% Commandes personnalisées
%--------------------------------------------------
\newcommand{\myparagraph}[1]{%
    \paragraph{#1} \mbox{} \\
    \vspace{-1em}
}

%--------------------------------------------------
% Listes
%--------------------------------------------------
\setlist[itemize,1]{label={\textbullet}}
\setlist[itemize,2]{label={$\blacktriangleright$}}

%--------------------------------------------------
% Divers / Commentaires
%--------------------------------------------------
% \usepackage{breakurl}


\title{Rapport de protection des données}

\onehalfspacing

\begin{document}


% ========================== Informations du rapport ==========================

\setlogo{images/LogoTPS.png}
\setunif{Télécom Physique Strasbourg}
\setsujet{Rapport de protection des données}
\settitre{Analyse de données cyberphysiques sur la distribution d'eau}
\seteleves{Nathan \textsc{Cerisara}\\Clément \textsc{Desberg}\\Ysée \textsc{Jacquet}\\Lucas \textsc{Levy}}

% ============================== Initialisation ===============================

\fairepagedegarde
\fairemarges

\newpage
% Numérotation
\pagenumbering{roman}
\setcounter{page}{1}

\tabledematieres
\listoffigures
% Table des tableaux (si nécessaire)
\listoftables

\section*{Abréviations employées}

\begin{itemize}
	\item \textbf{CART} : Classification And Regression Trees
    \item \textbf{CNN} : Convolutional Neural Network
	\item \textbf{CSV} : Comma Separated Values
	\item \textbf{FT Transformer} : Feature Tokenizer Transformer
	\item \textbf{KNN} : K-Nearest Neighbors
	\item \textbf{MLP} : Multi-Layer Perceptron
	\item \textbf{MCC} : Matthews Correlation Coefficient
	\item \textbf{NLP} : Natural Language Processing
\end{itemize}

% ============================= Corps du rapport ==============================

\newpage
% Numérotation
\pagenumbering{arabic}
\setcounter{page}{1}

\section*{Introduction}

Ce projet consiste en l'analyse de données cyberphysiques issues d'un système de distribution d'eau potable \cite{dataset}.
L'objectif principal est de développer et d'évaluer des modèles de machine learning capables de détecter et de classer les anomalies dans le système, telles que les attaques informatiques ou les défaillances physiques.
Les consignes du projet prévoient l'implémentation de K-Nearest Neighbors (KNN), Random Forest, XGBoost et Multi-Layer Perceptron (MLP) et Classification And Regression Trees (CART).
Il est également possible de remplacer l'un de ces modèles par un ou plusieurs autres au choix, ce qui a été fait en implémentant des modèles basés sur des transformeurs (Tab Transformer et FT Transformer) ainsi qu'un MLP avec attention à la place du modèle CART.
Finalement, les performances des modèles développés ont été comparées avec celles fournies dans l'article de référence \cite{article_reference}.

%  ---------------------- I. Données ----------------------

\section{Données}

L'ensemble des données comprend 5 fichiers Comma Separated Values (CSV) sur les relevés physiques et 5 fichiers CSV sur les relevés réseau.
Dans chaque cas, il y a un fichier de mesures prises en période normale – sans anomalie – et 4 fichiers de mesures prises en période anormale, avec des anomalies correspondant au type de données (attaques informatiques ou défaillances physiques).
Le sujet de chaque fichier est résumé dans la \hyperref[tab:files]{Table 1} ci-dessous :

\begin{table}[h]
	\centering
	\begin{tabular}{|l|l|}
		\hline
		\textbf{Fichier} & \textbf{Contenu} \\
		\hline
		\texttt{normal.csv}  & Acquisitions du traffic réseau en période normale \\
		\hline
		\texttt{phy\_norm.csv}  & Acquisitions des mesures physiques en période normale \\
		\hline
		\texttt{attack\_1.csv}  & Première acquisition du traffic réseau avec anomalies \\
		\hline
		\texttt{dataset\_att\_1.csv}  & Première acquisition des mesures physiques avec anomalies \\
		\hline
		\texttt{attack\_2.csv}  & Deuxième acquisition du traffic réseau avec anomalies \\
		\hline
		\texttt{dataset\_att\_2.csv}  & Deuxième acquisition des mesures physiques avec anomalies \\
		\hline
		\texttt{attack\_3.csv}  & Troisième acquisition du traffic réseau avec anomalies \\
		\hline
		\texttt{dataset\_att\_3.csv}  & Troisième acquisition des mesures physiques avec anomalies \\
		\hline
		\texttt{attack\_4.csv}  & Quatrième acquisition du traffic réseau avec anomalies \\
		\hline
		\texttt{dataset\_att\_4.csv}  & Quatrième acquisition des mesures physiques avec anomalies \\
		\hline
	\end{tabular}
	\caption{Aperçu des fichiers de données fournis, d'après le fichier fourni \texttt{README.xlsx}}
	\label{tab:files}
	\end{table}

Il y a également des fichiers packet capture (PCAP) fournis pour les données réseau, mais ceux-ci n'ont pas été utilisés dans le cadre de ce projet.

% ------- I.1 Visualisation et analyse des données --------

\subsection{Visualisation et analyse des données}

\subsubsection{Présentation générale des données}

Dans chaque fichier CSV, une ligne représente un ensemble de données collectées à un instant donné, tandis que les colonnes renvoient à différentes informations relevées ou différents dispositifs sur lesquels une mesure a été faite.
Chaque ligne est associée à une étiquette (\texttt{label}) indiquant si les données correspondent à un état normal (étiquette \texttt{normal} ou altérée en \texttt{nomal}) ou à une anomalie (étiquettes \texttt{anomaly}, \texttt{DoS}, \texttt{MITM}, \texttt{scan} ou \texttt{physical fault}).
La répartition globale peut être observée dans la \hyperref[fig:data_repartition]{Figure 1}, tandis que le détail de la répartition des étiquettes peut être consulté dans la \hyperref[tab:labels_repartition]{Table 2}.\\

\begin{figure}[H]
	\centering
	\includegraphics[width=0.75\textwidth]{images/data_repartition.png}
	\caption{Nombre d'entrées catégorisées \texttt{normal} et \texttt{attack} dans les jeux de données}
	\label{fig:data_repartition}
\end{figure}

\begin{table}[h]
	\centering
	\begin{tabular}{|l|rrr|}
		\hline
		\textbf{Étiquette} & \textbf{Données totales} & \textbf{Données réseau} & \textbf{Données physiques} \\
		\hline
		normal          & 20 461 956 & 20 453 299 & 8 657 \\
		nomal           & 249        & 0          & 249 \\
		\hline
		\textbf{Total normales} & \textbf{20 462 205} & \textbf{20 453 299} & \textbf{8 906} \\
		\hline
		DoS             & 5 671 852  & 5 671 542  & 310 \\
		MITM            & 2 156 417  & 2 155 409  & 1 008 \\
		physical fault  & 1 549 189  & 1 548 504  & 685 \\
		anomaly         & 389        & 389        & 0 \\
		scan            & 75         & 61         & 14 \\
		\hline
		\textbf{Total attaques} & \textbf{9 377 922}  & \textbf{9 375 905}  & \textbf{2 017} \\
		\hline
		\textbf{TOTAL} & \textbf{29 840 127} & \textbf{29 829 204} & \textbf{10 923} \\
		\hline
	\end{tabular}
	\caption{Répartition des données par label}
	\label{tab:labels_repartition}
\end{table}

\subsubsection{Présentation des données réseau}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.75\textwidth]{images/article/nb_samples_network.png}
	\caption{Nombre d'entrées par fichier de données réseau d'après \cite{article_reference}}
	\label{fig:net_number_entries}
\end{figure}

Au nombre de 14, les colonnes des données réseau sont listées dans la \hyperref[tab:network_features]{Table 4} (une traduction du tableau original présent dans \cite{article_reference}).

\begin{table}[h!]
	\centering
	\resizebox{\textwidth}{!}{%
	\begin{tabular}{|c|l|l|}
		\hline
		\textbf{N°} & \textbf{Nom} & \textbf{Description} \\ \hline
		1  & Time & Date d'acquisition \\ \hline
		2  & Src IP address & Adresse IP source \\ \hline
		3  & Dst IP adress & Adresse IP destination \\ \hline
		4  & Src MAC address & Adresse MAC source \\ \hline
		5  & Dst MAC address & Adresse MAC destination \\ \hline
		6  & Src Port & Port source \\ \hline
		7  & Dst Port & Port destination \\ \hline
		8  & Proto & Protocole \\ \hline
		9  & TCP flags & CWR | ECN | URG | ACK | PSH | RST | SYN | FIN flags \\ \hline
		10 & Payload size & Taille de la charge utile \\ \hline
		11 & MODBUS code & Code de fonction MODBUS \\ \hline
		12 & MODBUS value & Valeur réponse MODBUS \\ \hline
		13 & num\_pkts\_src & Nombre de paquets de la même addresse source durant les 2 dernières secondes \\ \hline
		14 & num\_pkts\_dst & Nombre de paquets de la même addresse destination durant les 2 dernières secondes \\ \hline
	\end{tabular}
	}
	\caption{Caractéristiques des données réseau}
	\label{tab:network_features}
\end{table}

\subsubsection{Présentation des données physiques}

En s'appuyant sur les informations fournies par \cite{article_reference}, on peut dénombrer les nombre de lignes pour chaque jeu de données physique comme présenté dans la \hyperref[fig:phys_number_entries]{Figure 2}.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.75\textwidth]{images/article/nb_samples_physical.png}
	\caption{Nombre d'entrées par fichier de données physiques d'après \cite{article_reference}}
	\label{fig:phys_number_entries}
\end{figure}

On constate que le fichier \texttt{phy\_norm.csv} contient un total de \textbf{3 429} entrées, tandis que les fichiers d'attaques contiennent entre 1 2000 et 2 421 entrées chacun, et sont donc plus petits lorsque pris indépendamment.
Cela est expliqué dans \cite{article_reference} par le fait que les périodes d'attaques sont plus courtes que la périodes normale qui a été relevée :

\begin{table}[h!]
	\centering
	\resizebox{\textwidth}{!}{%
	\begin{tabular}{|l}
		\textit{Specifically, the first acquisition lasts 1 hour and shows a total of 12 process cycles: it} \\
		\textit{refers to the WDT while working in normal conditions without any attack. On the} \\
		\textit{contrary, the remaining three acquisitions, which last 60 minutes, provide 8, 7 and 4} \\
		\textit{process cycles respectively.}
	\end{tabular}
	}
	\label{tab:quote}
\end{table}

Les mesures physiques sont reportées toutes les secondes et concernent des paramètres tels que l'état des pompes, les valeurs de différents capteurs, etc.
En tout, il y a 41 caractéristiques, présentées dans la \hyperref[tab:physical_features]{Table 3} (une traduction du tableau original présent dans \cite{article_reference}).

\begin{table}[h!]
	\centering
	\begin{tabular}{|c|l|l|}
		\hline
		\textbf{N°} & \textbf{Nom} & \textbf{Description} \\ \hline
		1  & Time & Date d'acquisition \\ \hline
		2-9  & Tank\_i & Valeur du capteur de presion du réservoir i (i allant de 1 à 8) \\ \hline
		10-15  & Pump\_i & État de la pompe i (i allant de 1 à 6) \\ \hline
		16-19  & Flow\_sensor\_i & Valeur du capteur de débit i (i allant de 1 à 4) \\ \hline
		20-41  & Valv\_i & État de l'électrovanne i (i allant de 1 à 22) \\ \hline
	\end{tabular}
	\caption{Caractéristiques des données physiques}
	\label{tab:physical_features}
\end{table}

% ------------ I.2 Pré-traitement des données -------------

\subsection{Pré-traitement}
\label{label:preprocessing}

L'ensemble des données est soumis a un pré-traitement général avant d'être utilisé par les différents modèles :

\begin{enumerate}
	\item Les données brutes (physique et réseau) sont chargées depuis les différents fichiers CSV.
	\item Les jeux de données étant particulièrement lourds, ils sont sous-échantillonnés pour permettre de travailler sur des sous-ensembles réduits.
	\item Les caractéristiques et les labels sont extraits.
	\item Les labels sont encodés avec \texttt{LabelEncoder} de \texttt{scikit-learn} \cite{scikit-learn}, ce qui permet de convertir les étiquettes textuelles en valeurs numériques.
	\item Les données sont stratifiées en ensembles d'entraînement, de validation et de test avec \texttt{train\_test\_split} de \texttt{scikit-learn}, en utilisant les options de \texttt{stratify} et \texttt{shuffle} pour garantir une répartition équilibrée des classes dans chaque ensemble.
		  Le ratio utilisé est de 70\% pour l'ensemble d'entraînement, 15\% pour l'ensemble de validation et 15\% pour l'ensemble de test.
	\item Si le \textit{balancing} est activé, il est appliqué sur l'ensemble d'entraînement à l'aide de la fonction \texttt{RandomOverSampler} de la bibliothèque \texttt{imbalanced-learn} \cite{imbalanced-learn}.
	\item Enfin, les données sont normalisées avec \texttt{StandardScaler} de \texttt{scikit-learn} pour garantir que chaque caractéristique ait une moyenne nulle et une variance unitaire.
\end{enumerate}

% ------------ II. Application des algorithmes ------------

\section{Application des algorithmes}

% --------------- II.1 Algorithmes utilisés ---------------

\subsection{Algorithmes utilisés}

	Au total, 7 algorithmes différents ont été implémentés pour ce projet.
	Pour trois d'entre eux, deux tailles de modèles ont été testées : \texttt{small} et \texttt{medium} ; les autres n'ont été testés qu'en taille \texttt{small}.
	Cela sera expliqué plus en détail dans la section \hyperref[sec:hyperparameters]{3.3 Hyperparamètres et résultats}.

Parmi les modèles demandés, les suivants ont été implémentés :
\begin{itemize}
    \item \textbf{KNN} (en \texttt{small}, \texttt{medium} et \texttt{large})
    \item \textbf{Random Forest} (en \texttt{small},  \texttt{medium} et \texttt{large})
    \item \textbf{XGBoost} (en \texttt{small} et \texttt{medium})
    \item \textbf{MLP} (en \texttt{small}, \texttt{medium} et \texttt{large})
\end{itemize}

Le modèle CART n'a pas été implémenté, mais a été remplacé par les trois modèles ci-dessous :

\begin{itemize}
	\item \textbf{Tab Transformer} (en \texttt{small} et \texttt{medium}) : modèle basé sur des transformeurs appliqués aux données tabulaires, utilisant des embeddings pour les variables catégorielles et un mécanisme d’auto-attention pour capturer les interactions entre les caractéristiques.
	\item \textbf{FT Transformer} (en \texttt{small} et \texttt{medium}) : variante optimisée du transformeur pour données tabulaires, combinant embeddings de caractéristiques et couches d’auto-attention avec une tête de prédiction dédiée, offrant de bonnes performances tout en restant peu coûteuse en calcul.
	\item \textbf{MLP avec attention} (en \texttt{small}, en \texttt{medium} et \texttt{large}) : même architecture que le MLP classique, mais avec un mécanisme d'attention ajouté.
\end{itemize}

% ---------- II.2 Organisation des entraînements ----------

\subsection{Organisation des entraînements}

L'ensemble du code est organisé pour permettre une expérimentation facile et reproductible des différents modèles sur les deux types de données.

Les données sont pré-traitées de manière cohérente pour tous les modèles (voir \hyperref[label:preprocessing]{1.2 Pré-traitement}), et un système de cache est mis en place pour éviter de répéter le pré-traitement lors de nouvelles exécutions.
Il est enregistré dans le dossier \texttt{cached\_datasets}.

Chaque modèle est défini dans un script séparé contenu dans un dossier \texttt{models/}, avec des configurations spécifiques (\texttt{configs/model\_type/config\_name.yaml}) pour chaque type de modèle : hyperparamètres, jeux de données, taille des modèles, etc.
Les scripts d'entraînement et de test sont situés dans les fichiers \texttt{scripts/train.py} et \texttt{scripts/test.} \texttt{py}.
Les différents modèles sont entraînés individuellement avec leur script d'entraînement et leur fichier de configuration, ou bien plusieurs modèles peuvent être entraînés simultanément avec le script \texttt{scripts/train\_all.py}.

Les résultats de chaque entraînement sont enregistrés de manière structurée dans le dossier \texttt{experiments} en fonction de leur configuration, permettant une analyse et une comparaison faciles des performances des modèles.
Le détail des résultats enregistrés est présenté dans la section suivante.

% ----------- II.3 Hyperparamètres et résultats -----------

\subsection{Hyperparamères et résultats}
\label{sec:hyperparameters}

En termes d'hyperparamètres, il n'y en a qu'un seul qui a été vraiment manipulé : la taille des modèles utilisés.
En effet, pour chaque type de modèle implémenté, deux ou trois tailles de modèles ont été testées : \texttt{small}, \texttt{medium} et parfois \texttt{large}.
La différence principale entre elles réside dans le nombre de couches et de neurones utilisés et le nombre de données utilisées pour l'apprentissage (il faut \textit{scaler} avec la taille du modèle). Cependant, en vue de la taille du dataset physical, l'on ne scale que sur le network, et on utilise tout le temps toutes les données du physical.
Par exemple, pour le MLP, le modèle \texttt{small} utilise 2 couches cachées avec 32 et 64 neurones et entraîné sur 300.000 données network, tandis que le modèle \texttt{medium} utilise 3 couches cachées de 64, 128 et 256 neurones et entraîné sur 500.000 données network.

Concernant les résultats, sont enregistrés :

\begin{itemize}
	\item les poids du meilleur modèle,
	\item la configuration utilisée (au cas où les configurations changent),
	\item Les métriques sur les jeux de données d'entraînement, validation et test du meilleur modèle,
	\item Les erreurs sur les jeux de données d'entraînement, validation et test du meilleur modèle,
	\item Les courbes de loss et d'accuracy sur les jeux de donnée d'entraînement et de validation.
\end{itemize}

Deux rapports récapitulatifs de tous les entraînements sont ensuite générés avec le script \texttt{src/analyze\_results.py}, un pour les jeux de données physiques \texttt{results\_analysi} \texttt{s/physical/report.md} et un pour les jeux de données réseaux \texttt{results\_analysis/netwo} \texttt{rk/report.md}.
On y trouve :

\begin{itemize}
	\item un tableau comparatif des performances de chaque modèle, ordonné par F1-score (macro) décroissant,
	\item un tableau récapitulatif des classes mal classées par chaque modèle, ordonné par taux d'erreur décroissant,
	\item un tableau récapitulatif du top 20 des entrées les moins bien classés sur l'ensemble des modèles, avec la prédiction majoritaire,
	\item une matrices de corrélation des erreurs entre les différents modèles,
	\item l'ensemble des courbes d'entraînement pour tous les modèles.
\end{itemize}

% -------------------- III. Résultats ---------------------

\section{Évaluation et comparaison avec les données de référence}

% ----------------- III.1 Données réseau ------------------

\subsection{Données réseau}

% ---------------- III.2 Données physiques ----------------

\subsection{Données physiques}

D'après les résultats présentés dans la \hyperref[tab:physical_small_results]{Table 5}, le modèle \texttt{small\_knn} obtient les meilleures performances sur le jeu de données \texttt{physical\_small}, avec une précision de \textbf{97,74\%}, un F1-macro de \textbf{0,8007}, une précision équilibrée de \textbf{0,8235} et un MCC de \textbf{0,9402}.
Le temps d'entraînement est également très faible (quasi-instantané), ce qui en fait un choix efficace pour ce type de données.
À l'inverse, le modèle \texttt{small\_random\_forest} affiche les performances les plus faibles, ce qui peut s'expliquer par une répartition des classses TO COMPLETE.

\begin{table}[H]
    \centering
	\resizebox{\textwidth}{!}{%
    \begin{tabular}{c l c c c c c}
    	\hline
    	\textbf{Rang} & \textbf{Modèle} & \textbf{Précision} & \textbf{F1 (macro)} & \textbf{Précision équilibrée} & \textbf{MCC} & \textbf{Temps (s)} \\
    	\hline
    	1 & \texttt{small\_knn} & 0.9774 & 0.8007 & 0.8235 & 0.9402 & 0.0 \\
    	2 & \texttt{small\_tab\_transformer} & 0.9683 & 0.8001 & 0.8250 & 0.9188 & 40.7 \\
    	3 & \texttt{small\_attention\_mlp} & 0.9048 & 0.7259 & 0.8106 & 0.7946 & 35.2 \\
    	4 & \texttt{small\_mlp} & 0.8786 & 0.6889 & 0.7988 & 0.7515 & 22.7 \\
    	5 & \texttt{small\_ft\_transformer} & 0.8401 & 0.6593 & 0.7970 & 0.7004 & 56.1 \\
    	6 & \texttt{small\_xgboost} & 0.8676 & 0.6412 & 0.7906 & 0.7287 & 0.6 \\
    	7 & \texttt{small\_random\_forest} & 0.6101 & 0.4687 & 0.7242 & 0.4779 & 0.2 \\
    	\hline
    \end{tabular}
	}
	\caption{Comparaison des expériences sur le jeu de données physiques physical\_small}
    \label{tab:physical_small_results}
\end{table}

En comparant les résultats obtenus avec ceux de l'article de référence \cite{article_reference}, on constate que nos modèles TO COMPLETE.
En effet dans la \hyperref[tab:results_physical]{Table 6}, on peut voir que les performances des KNN, Random Forest, SVM et Naive Bayes (NB) sont TO COMPLETE.

\begin{table}[ht]
	\centering
	\begin{tabular}{lcccc}
		\hline
		\textbf{Algorithme} & \textbf{Exactitude} & \textbf{Rappel} & \textbf{Précision} & \textbf{F1-score}\\
		\hline
		KNN & 0,98 & 0.95 & 0,95 & 0,95\\
		RF  & 0,99 & 0,98 & 0,95 & 0,97\\
		SVM & 0,93 & 0,92 & 0,64 & 0,75\\
		NB  & 0,93 & 0,92 & 0,66 & 0,77\\
		\hline
	\end{tabular}
	\caption{Résultats de l’évaluation des algorithmes d’apprentissage automatique sur le jeu de données physique}
	\label{tab:results_physical}
\end{table}

En s'attardant sur les erreurs commises par les différents modèles, on peut observer certaines corrélation entre celles-ci, comme le montre la \hyperref[fig:corrmat_physical]{Figure 4}.
Par exemple — et sasns surprise — le modèle MLP et le modèle MLP avec attention présentent une forte corrélation dans leurs erreurs.

\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{images/correlation_heatmap/physical.png}
	\caption{Matrice de corrélation des erreurs entre les modèles pour les données physiques}
	\label{fig:corrmat_physical}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{images/correlation_heatmap/network.png}
	\caption{Matrice de corrélation des erreurs entre les modèles pour les données réseau}
	\label{fig:corrmat_network}
\end{figure}

Comme il y a très peu de faible corrélations, il est raisonnable de penser que certains échantillons sont systématiquement mal classés par tous les modèles.
La \hyperref[tab:misclassified_samples_physical]{Table 6} liste les échantillons qui ont été mal classés par l'ensemble des modèles lors de nos différentes exécutions, ainsi que la prédiction majoritaire effectuée par les modèles pour ces échantillons.
Heureusement, on constate que leur nombre est très faible — seulement 17 échantillons sur un total de X — donc il n'y a pas beaucoup d'entrées réellement problématiques.

On remarque que la majorité des échantillons mal classés appartiennent à la classe \texttt{normal}, ce qui indique que les modèles ont du mal à distinguer les échantillons normaux des anomalies dans certains cas.
Cela peut s'expliquer par le fait que les mesures sont effectuées toutes les secondes, et donc la limite entre un état normal et un état anormal peut être très fine.
Il y a également des des échantillons mal classés appartenant à la classe \texttt{scan} qui est sous-représentée, ce qui peut expliquer les difficultés rencontrées par les modèles pour les classer correctement.
De même, l'étiquiette \texttt{scan} est plusieurs fois prédite de manière erronée, ce qui montre bien que les modèles ont du mal à savoir à quoi correspond cette classe.

\begin{table}[H]
	\centering
	\begin{tabular}{c l c l}
		\hline
		\textbf{Entrée} & \textbf{Label réel} & \textbf{Nombre d'erreurs} & \textbf{Prédiction majoritaire} \\
		\hline
		36   & scan   & 10 & normal \\
		768  & normal & 10 & physical fault \\
		848  & normal & 10 & physical fault \\
		927  & normal & 10 & MITM \\
		1257 & normal & 10 & physical fault \\
		1549 & scan   & 10 & normal \\
		\hline
	\end{tabular}
	\caption{Échantillons physiques systématiquement mal classés lors des différentes exécutions}
	\label{tab:misclassified_samples_physical}
\end{table}

% TO MODIFY
\begin{table}[H]
	\centering
	\begin{tabular}{c l c l}
		\hline
		\textbf{Entrée} & \textbf{Label réel} & \textbf{Nombre d'erreurs} & \textbf{Prédiction majoritaire} \\
		\hline
		TO COMPLETE & TO COMPLETE & TO COMPLETE & TO COMPLETE \\
		\hline
	\end{tabular}
	\caption{20 échantillons réseau systématiquement mal classés lors des différentes exécutions}
	\label{tab:misclassified_network}
\end{table}

\section*{Conclusion}

\newpage

\section*{Retour personnel : CERISARA Nathan}

\subsection*{Contribution}

Dans ce pojet, j'ai principalement travaillé à développer l'architecture modulaire dont je suis très fier pour l'entraînement et le test des modèles, et le script qui va automatiquement analyser les résultats et les afficher dans un rapport markdown et les mettre à disposition de l'app streamlit. J'ai entraîné les modèles sur mon ordinateur fixe (Ryzen 5 3600, 24 Go de RAM, GTX Titan X) et j'ai surveillé les entraînements et modifié certaines configurations pour faire que certains modèles apprennent mieux et réduire l'overfitting.

\subsection*{Avis}

J'ai pas appris grand chose avec ce projet, je savais déjà analyser / traiter des données, et je savais déjà mettre en place une pipeline d'entraînement de modèles. Si on avait eu le temps (pas eu à faire 7 projets en même temps dont 2 très gros et très importants), j'aurais peut-être pu aller plus loin dans le concept de prédiction d'attaque et de détection d'anomalie, et de mettre en place des méthodes que l'on n'utilise que dans ces domaines, mais je n'ai donc pas eu le temps de regarder cela.

\newpage

\section*{Retour personnel : DESBERG Clément}

\subsection*{Contribution}

\subsection*{Avis}

\newpage

\section*{Retour personnel : JACQUET Ysée}

\subsection*{Contribution}

\subsection*{Avis}

\newpage

\section*{Retour personnel : LEVY Lucas}

\subsection*{Contribution}

\subsection*{Avis}

\newpage

\printbibliography[heading=bibintoc, title={Références}]
\addcontentsline{toc}{section}{Références}

\end{document}