# Physical Data - Large Config (Full Scale Training)
# Maximum performance, longer training time

data:
  dataset_type: physical
  train_ratio: 0.7
  val_ratio: 0.15
  test_ratio: 0.15
  balancing: smote  # Best synthetic oversampling
  n_samples: null  # Use all samples
  normalize: true
  seed: 42

model:
  name: xgboost  # Change to desired model
  hyperparameters:
    # XGBoost large config
    n_estimators: 500
    max_depth: 12
    learning_rate: 0.05
    subsample: 0.9
    colsample_bytree: 0.9
    min_child_weight: 2
    reg_alpha: 0.1
    reg_lambda: 1.0

training:
  # For neural networks
  epochs: 200
  batch_size: 16
  learning_rate: 0.0005
  optimizer: adamw
  weight_decay: 0.00001
  scheduler: cosine
  early_stopping: true
  patience: 20
  use_gpu: true

experiment:
  name: physical_large
  save_predictions: true
  save_history: true
  save_model: true
