# ATTENTION_MLP - Physical Data - Large Config
# Auto-generated by generate_configs.py

data:
  dataset_type: physical
  train_ratio: 0.7
  val_ratio: 0.15
  test_ratio: 0.15
  balancing: smote
  normalize: true
  seed: 42
model:
  name: attention_mlp
  hyperparameters:
    hidden_dim: 128
    n_heads: 8
    mlp_layers:
    - 256
    - 128
    - 64
    dropout: 0.3
training:
  epochs: 200
  batch_size: 16
  learning_rate: 0.0005
  optimizer: adamw
  weight_decay: 0.0001
  scheduler: cosine
  early_stopping: true
  patience: 3
  use_gpu: true
experiment:
  name: physical_large
  save_predictions: true
  save_history: true
  save_model: true
