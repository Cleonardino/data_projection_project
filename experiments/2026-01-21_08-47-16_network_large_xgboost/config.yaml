data:
  balancing: class_weights
  dataset_type: network
  normalize: true
  nrows_per_file: 800000
  seed: 42
  test_ratio: 0.15
  train_ratio: 0.7
  val_ratio: 0.15
experiment:
  name: network_large
  save_history: true
  save_model: true
  save_predictions: true
model:
  hyperparameters:
    learning_rate: 0.05
    max_depth: 12
    n_estimators: 500
    reg_lambda: 1.0
    subsample: 0.9
  name: xgboost
training:
  batch_size: 16
  early_stopping: true
  epochs: 200
  learning_rate: 0.0005
  optimizer: adamw
  patience: 3
  scheduler: cosine
  use_gpu: true
  weight_decay: 0.0001
